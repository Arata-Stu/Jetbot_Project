{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "229651f7-773b-4222-9e1a-7f4a18bda494",
   "metadata": {},
   "source": [
    "## モデルの学習 by Pytorch\n",
    "GPUないときついかも  \n",
    "モデルはテキトー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa12ecbc-fb27-472a-9b60-1c9d6c7e5122",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 192\u001b[0m\n\u001b[1;32m    190\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m--> 192\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m train(model, train_loader, criterion, optimizer, device)\n\u001b[1;32m    193\u001b[0m     test_loss, test_acc \u001b[38;5;241m=\u001b[39m test(model, test_loader, criterion, device)\n\u001b[1;32m    195\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[1], line 154\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m    152\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m    153\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m--> 154\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    155\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    157\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/image/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/image/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# カスタムデータセットクラス\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.classes = ['left_near', 'left_just', 'left_far', \n",
    "                        'middle_near', 'middle_just', 'middle_far', \n",
    "                        'right_near', 'right_just', 'right_far']\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        for idx, class_name in enumerate(self.classes):\n",
    "            class_dir = os.path.join(self.data_dir, class_name)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                self.images.append(os.path.join(class_dir, img_name))\n",
    "                self.labels.append(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# データ変換ルールの定義\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 全データセットのロード\n",
    "full_dataset = CustomDataset(data_dir='../class/classes', transform=transform)\n",
    "\n",
    "# データセットの長さ\n",
    "dataset_size = len(full_dataset)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "# トレーニングセットとテストセットに分割\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "# データローダーの定義\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels * self.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * self.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "model = ResNet50()\n",
    "\n",
    "\n",
    "# GPUの利用確認\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# モデルをデバイスに移動\n",
    "model = ResNet50().to(device)\n",
    "\n",
    "# 損失関数とオプティマイザの定義\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# トレーニングとテスト関数\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return running_loss / len(train_loader), correct / total\n",
    "\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return running_loss / len(test_loader), correct / total\n",
    "\n",
    "# トレーニングとテストの結果を記録\n",
    "train_losses = []\n",
    "train_accuracy = []\n",
    "test_losses = []\n",
    "test_accuracy = []\n",
    "\n",
    "# トレーニングループ\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = test(model, test_loader, criterion, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracy.append(train_acc)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracy.append(test_acc)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}')\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}')\n",
    "\n",
    "# 結果のグラフ表示\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.title('Loss over epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracy, label='Train Accuracy')\n",
    "plt.plot(test_accuracy, label='Test Accuracy')\n",
    "plt.title('Accuracy over epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17cf176-39d0-425f-9e7f-d7bd1ff896a0",
   "metadata": {},
   "source": [
    "## 訓練したモデルを利用し、予測\n",
    "新しい画像を用いて、出力を確認してみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518260f8-5f28-4e02-b134-539781e9b31c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def predict(image_path):\n",
    "# 新しい画像の読み込み\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "    # 画像の前処理\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # バッチ次元の追加\n",
    "\n",
    "    # デバイスの設定\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    image = image.to(device)\n",
    "\n",
    "    # モデルの評価モード\n",
    "    model.eval()\n",
    "\n",
    "    # 予測\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # クラス名の取得\n",
    "    classes = ['left_near', 'left_just', 'left_far', \n",
    "               'middle_near', 'middle_just', 'middle_far', \n",
    "               'right_near', 'right_just', 'right_far']\n",
    "    predicted_class = classes[predicted.item()]\n",
    "\n",
    "    print(f'Predicted Class: {predicted_class}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75485cfd-c12d-4da6-8998-59b3504b5ac0",
   "metadata": {},
   "source": [
    "## 画像のpathを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9478dd5-c32b-46d8-b3c9-303be7c6de39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "classes = ['left_near', 'left_just', 'left_far', \n",
    "               'middle_near', 'middle_just', 'middle_far', \n",
    "               'right_near', 'right_just', 'right_far']\n",
    "\n",
    "class_list =[]\n",
    "\n",
    "for s in classes:\n",
    "     class_list.append(glob.glob(\"./image/test/\"+s+\"/*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4959136e-f3eb-4f4b-9ac8-96f66884d716",
   "metadata": {},
   "source": [
    "## 取得したpathの画像を入力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc44815-65de-46a1-baa0-0412782a77c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(classes)):\n",
    "    print(\"Answer: {}\".format(classes[i]))\n",
    "    for im in class_list[i]:\n",
    "        \n",
    "        predict(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1261cc95-2e0c-4428-bc09-9a45efd08cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
